Learning in Public Series #5

When AI Feels Faster… But Slows You Down

Programmatic Engineer recently covered [a study showing that experienced developers were 19% slower when using AI tools like Cursor for bug fixes—despite believing they were working 24% faster](https://substack.com/home/post/p-169160664). Only one outlier showed a 40% productivity lift.

This gap between perceived and actual productivity fascinates me. Over the past year, I transitioned from managing engineers back to being an individual contributor. After 16 years working in infrastructure, applied AI, and data platforms, I’m now building customer-facing AI products. AI has been invaluable for quickly ramping up unfamiliar stacks and reducing activation costs. Paired with brilliant, supportive peers as code reviewers, I regained high development velocity fast.

Having gained competency in the tech stack and domain, I started rebalancing. I now spend more time systematically reading docs, mentally solving problems before coding, and watching for dopamine-driven, low-quality output. Occasionally, I choose to code manually to build technical muscle. I’ve also begun applying more prompt engineering techniques and adopting tips from others on integrating AI into workflows.

The real question I’m exploring: once competent in a domain, how do you achieve a true 40%+ or even 10x lift in productivity while deepening and scaling learning?

I don’t have the perfect answer yet, but my current mental models are:

- Task alignment: Pause to evaluate which parts to outsource to AI, sometimes breaking tasks down to leverage AI’s strengths versus my own.
- Prompt as craft: Treat prompts like code—iterate, refine, measure output quality, give specific instructions, and save good examples.
- Protect flow: Recognize context switches and manage them to minimize disruption. Use the waiting moments for low-focus tasks or brief reflection to keep deep work intact. If needed, step away from the computer and take a walk to regain focus.

Recently, I switched from Cursor to Claude Code. In upcoming posts, I’ll explore and share reflections from this new setup while flushing out my high-level mental models.